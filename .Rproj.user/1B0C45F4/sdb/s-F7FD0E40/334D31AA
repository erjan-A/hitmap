{
    "collab_server" : "",
    "contents" : "## Dependency package - if you do not have dplyr installed, you will need to execute\n## install.packages('dplyr') before running this line.\nlibrary(dplyr)\n\n## Set your working directory here: this should be the location where you saved trip_data_1.csv\nsetwd('~/Downloads')\n\n## This read.csv function reads in only the first 10K rows of the first trip data csv file. \n## The colClasses and comment.char arguments let the function know specifics about the csv \n## that let it read much faster, although it can read the file without these arguments.\n\ntripData <- read.csv('trip_data_1.csv', nrows = 10000, colClasses = c('character',\n    'character', 'character', 'integer', 'character', 'character', 'character',\n    'integer', 'integer', 'numeric', 'numeric', 'numeric', 'numeric', 'numeric'),\n    comment.char = '')\n\n    tripData <- select(tripData, pickup_longitude, pickup_latitude)\n\n#filter out longitude and latitude values that are way outside normal levels (bad data)\ntripData <- subset(tripData, (tripData$pickup_longitude > -74.1 & tripData$pickup_longitude < -73.7 & tripData$pickup_latitude < 60))\n\n## set.seed ensures we can reproduce 'random' selections by algorithms such as kmeans\nset.seed(12345)\n## this kmeans function chooses 20 random locations, then weighs distribution of tripset points by\n## those centroids and relocates the centroids repeatedly until the movement is near zero and they\n## represent fairly useful clusters of points.\nclusters <- kmeans(tripData, 20, nstart = 10)\n\n##--------------------------------##\n## NYCPlot\n##--------------------------------##\n\n## plot() creates a plot object with the original 10K points, by latitude and longitude\nplot(tripData, col = clusters$cluster)\n\n## points() appends a series of points to the open plot, taken from the clusters object centers\n## (which are given in latitude and longitude)\npoints(clusters$centers, col = 'red', pch = 10)\n\n## Convert Clusters$cluster to character vector to colorize in plot as a discrete variable rather than a continuous one\n## (Discrete variables automatically color in distinct color schemes and are easily distinguised; continuous ones show\n## up in shades of the same color to show gradation.  In this case, we want distinct colors so we convert to character vector)\nclusters$cluster <- as.character(clusters$cluster)\n\n## load the ggmap package to overlay points on top of a google map image\n## Dependency package - if you do not have ggmap installed, you will need to execute\n## install.packages('ggmap') before running this line.\nlibrary(ggmap)\n## Retrieve the map data for NYC based on longitude and latitude\nNYC = get_map(location = c(lon = -73.9, lat = 40.75), zoom = 11, maptype = 'roadmap')\n\n## render the map data as a plottable object\nmapVis <- ggmap(NYC)\nmapVis\n\n## overlay datapoints, color coded by cluster as a discrete variable\nmapVis <- mapVis + geom_point(data = tripData, aes(x = pickup_longitude, y = pickup_latitude, colour = clusters$cluster))\nmapVis\n\n\n##--------------------------------##\n## cost calculation\n##--------------------------------##\n\n## Now we'll create a linear model to approximate the distance traveled as a function of the net change in latitude and longitude\n## We'll read in the top 10K rows again and this time keep a different set of columns\n\ntripData2 <- read.csv('trip_data_1.csv', nrows = 10000, colClasses = c('character',\n    'character', 'character', 'integer', 'character', 'character', 'character',\n    'integer', 'integer', 'numeric', 'numeric', 'numeric', 'numeric', 'numeric'),\n    comment.char = '')\n\ntripData2 <- select(tripData2,\n                    trip_distance,\n                    pickup_longitude,\n                    pickup_latitude,\n                    dropoff_longitude,\n                    dropoff_latitude) %>%\n    ## Here we use the mutate() function to create a new covariate; the net change in latitude and longitude\n    mutate(latlong_traveled = sqrt((pickup_longitude - dropoff_longitude) ^ 2 + (pickup_latitude - dropoff_latitude) ^ 2))\n\n## Filter out the outlier data\ntripData2 <- subset(tripData2, (tripData2$pickup_longitude > -74.1 & tripData2$pickup_longitude < -73.7 & tripData2$pickup_latitude < 60))\ntripData2 <- subset(tripData2, latlong_traveled < 20)\n\ndist_model <- lm(trip_distance ~ latlong_traveled, data = tripData2)\n## Printing out the model gives us the model coefficients; the intercept and slope of the linear approximation\ndist_model\n\n## Plotting the model gives us a series of four diagnostic plots that indicate the quality of the model through representations of the point\n## residuals. These plots show that this model isn't really a very good approximation; that the residuals are high and skew the data considerably.\n## However, our concern is with aggregate approximation rather than single-case precision, so this works well enough.\nplot(dist_model)\n\n##-------------------##\n## LM Plot\n##-------------------##\n## So let's see wht the approximation really looks like:\n## First we plot the 10000 data points, latlong traveled vs. actual trip distance\nplot(tripData2$latlong_traveled, tripData2$trip_distance)\n## Now we plot the points as they would be predicted by our linear model, using the predict() function\npoints(tripData2$latlong_traveled, predict(dist_model, newdata = tripData2), col = 'red', pch = 19, cex = .5)\n",
    "created" : 1462461979756.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "960718655",
    "id" : "334D31AA",
    "lastKnownWriteTime" : 1462335524,
    "last_content_update" : 1462335524,
    "path" : "~/Downloads/Exploration 8.22.02 AM.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 6,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}